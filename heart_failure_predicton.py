# -*- coding: utf-8 -*-
"""Heart_Failure_Predicton.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RqePLFNg1kmLIkxkeMWmtQa5BkmIbQwh

**Dataset Preparation**
"""

import pandas as pd # pandas is used to read files of the datasets
from sklearn.model_selection import train_test_split # train_test_split is used to part
from sklearn.naive_bayes import GaussianNB # GaussianNB() is the naive bayes classifier
from sklearn.svm import SVC # SVC() is the Support Vector Machines Classifier
from sklearn.neural_network import MLPClassifier # MLPClassifier us the Neural Network
from sklearn.metrics import confusion_matrix, classification_report # Confusion_matrix

df=pd.read_csv('heart.csv') # Read the dataset in a new data frame(df)
df.head() # Display the first five rows (5 premières lignes)

df.tail() # Display the last five rows (5 denières lignes)

df.info()

"""**LabelEncoder**"""

from sklearn.preprocessing import LabelEncoder
X = LabelEncoder() # created a instance of label encoder
df.Sex = X.fit_transform(df.Sex)
df.ChestPainType = X.fit_transform(df.ChestPainType)
df.RestingECG = X.fit_transform(df.RestingECG)
df.ExerciseAngina = X.fit_transform(df.ExerciseAngina)
df.ST_Slope = X.fit_transform(df.ST_Slope)

df.head(10)

# example of a normalization
from numpy import asarray
from sklearn.preprocessing import MinMaxScaler
# define data

print(df)
# define min max scaler
scaler = MinMaxScaler()
# transform data
scaled = scaler.fit_transform(df)
print(scaled)

X=df.drop('HeartDisease',axis=1) 
y=df['HeartDisease']
X.head()

# example of a normalization
from numpy import asarray
from sklearn.preprocessing import MinMaxScaler
# define data

# define min max scaler
scaler = MinMaxScaler()
# transform data
scaled = scaler.fit_transform(X)

df.corr()

"""**Partitioning DataPartitioning Data**"""

[X_train,X_test,y_train,y_test]=train_test_split(X,y,test_size=0.2)
print("Train dataset size: {}/{}".format(len(X_train),len(y)))
print("Test dataset size: {}/{}".format(len(X_test),len(y)))

"""**Machine Learning: NB Vs SVM Vs Neural Network**"""

gnb=GaussianNB() # gnb is a naive bayes classifier
linear_svm =SVC(kernel='linear') # linear_svm is a Linear Support Vectors
rbf_svm =SVC(kernel='rbf') # rbf_svm is a RBF support vectors
sigmoid_svm =SVC(kernel='sigmoid')# sigmoid support vectors
ploy_svm =SVC(kernel='poly',degree=2) # Ploynom with degree=2 as support vectors
neural=MLPClassifier(hidden_layer_sizes=(100,20),activation='relu',solver='adam')

gnb.fit(X_train,y_train) # Train Guassian NB classifier
linear_svm.fit(X_train,y_train) # Train SVM
rbf_svm.fit(X_train,y_train)
sigmoid_svm.fit(X_train,y_train)
ploy_svm.fit(X_train,y_train)
neural.fit(X_train,y_train) # Train Neural Network - finding the best weight matrix

y_nb=gnb.predict(X_test)
y_linear_svm=linear_svm.predict(X_test)
y_rbf_svm=rbf_svm.predict(X_test)
y_ploy_svm=ploy_svm.predict(X_test)
y_sigmoid_svm=sigmoid_svm.predict(X_test)
y_neural=neural.predict(X_test)

"""**Performance Evaluation**"""

print ('************* Peformance Evauation of Naive Bayes **************')
print(confusion_matrix(y_test,y_nb))
print(classification_report(y_test,y_nb))
print ('************* Peformance Evauation of Linear SVM **************')
print(confusion_matrix(y_test,y_linear_svm))
print(classification_report(y_test,y_linear_svm))
print ('************* Peformance Evauation of RBF SVM **************')
print(confusion_matrix(y_test,y_rbf_svm))
print(classification_report(y_test,y_rbf_svm))
print ('************* Peformance Evauation of Sigmoid SVM **************')
print(confusion_matrix(y_test,y_sigmoid_svm))
print(classification_report(y_test,y_sigmoid_svm))
print ('************* Peformance Evauation of Polynomial (2) SVM **************')
print(confusion_matrix(y_test,y_ploy_svm))
print(classification_report(y_test,y_ploy_svm))
print ('************* Peformance Evauation of Neural Network **************')
print(confusion_matrix(y_test,y_neural))
print(classification_report(y_test,y_neural))

import pickle
with open('model.pickle', 'wb') as handle:
    pickle.dump(gnb, handle)

with open('/content/model.pickle', 'rb') as handle:
    b = pickle.load(handle)

b.predict(X_test)
